# Proyecto_final_mlops
1) DescripciÃ³n corta

Construimos un modelo para detectar billetes falsos usando el dataset Banknote Authentication de UCI. El dataset ya viene en formato tabular (no hay imÃ¡genes): cada fila representa un billete y sus columnas son estadÃ­sticos calculados sobre la textura del billete (a partir de una transformada wavelet).

2) Problema y objetivo de negocio

Dolor del negocio: las entidades pueden sufrir pÃ©rdidas por aceptar billetes falsos en caja o cajeros.
Objetivo: reducir el riesgo operativo y las pÃ©rdidas mediante un clasificador que ayude a identificar billetes falsos.

3) Dataset y fuente

Nombre: Banknote Authentication

Fuente (UCI): https://archive.ics.uci.edu/ml/datasets/banknote+authentication

Descarga directa (CSV):
https://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt

TamaÃ±o aproximado: 1.372 filas Ã— 5 columnas

4) Significado de columnas

| Columna      | Â¿QuÃ© mide? (intuitivo)                         | Pista tÃ­pica para fraude                                          |
| ------------ | ---------------------------------------------- | ----------------------------------------------------------------- |
| **variance** | **Contraste/variaciÃ³n** de la textura          | AutÃ©nticos suelen tener **> 0**; falsos, **< 0**                  |
| **skewness** | **InclinaciÃ³n** de la distribuciÃ³n (cola)      | AutÃ©nticos: **positiva** (cola derecha); falsos: **0 o negativa** |
| **curtosis** | **Pico** y **colas largas** (valores extremos) | **Alta** aparece mÃ¡s en **falsos**                                |
| **entropy**  | **Desorden/variedad** de la textura            | Muy parecida en ambos; **no separa sola**                         |
| **class**    | Etiqueta objetivo                              | **0 = autÃ©ntico**, **1 = falso**                                  |


variance:mide cuÃ¡nta dispersiÃ³n tienen los coeficientes, valores altos â†’ mucha variaciÃ³n/contraste en la textura; valores bajos â†’ textura mÃ¡s uniforme.

skewness:mide si la distribuciÃ³n es simÃ©trica o si tiene cola mÃ¡s larga a un lado, mucha asimetrÃ­a = presencia de coeficientes atÃ­picos (bordes/texturas raras).

curtosis:mide cuÃ¡n â€œpicudaâ€ es la distribuciÃ³n y quÃ© tan pesadas son sus colas, curtosis alta sugiere patrones muy marcados en la textura (posible seÃ±al de falsificaciÃ³n).

entropy: mide complejidad de los coeficientes,mÃ¡s cerca de 0 = mayor entropÃ­a.

5) MÃ©tricas de Ã‰xito

Exactitud (Accuracy): el modelo debe alcanzar al menos 90%.

Recall en clase â€œfalsoâ€: prioridad que el modelo detecte mÃ¡s del 95% de billetes falsos, para minimizar riesgos de aceptar uno.

Alcance del Proyecto

MVP: construir un modelo de clasificaciÃ³n en Jupyter Notebook, validado con mÃ©tricas bÃ¡sicas.

Futuro: integrar en un pipeline MLOps con orquestaciÃ³n, despliegue y monitoreo.

6) Timeline y Responsables

| Fase | Actividad                                        | Responsable       | Tiempo estimado |
| ---- | ------------------------------------------------ | ----------------- | --------------- |
| 1    | RevisiÃ³n del dataset y EDA                       | Carolina Restrepo | 1 semana        |
| 2    | Preprocesamiento y entrenamiento de modelos base | Carolina Restrepo | 1 semana        |
| 3    | EvaluaciÃ³n, documentaciÃ³n y presentaciÃ³n         | Carolina Restrepo | 4 dÃ­as          |

7) Estrategia de Preprocesamiento

VerificaciÃ³n y eliminaciÃ³n de nulos (no aplicÃ³ en este dataset).

NormalizaciÃ³n de variables numÃ©ricas para modelos sensibles a escala.

SeparaciÃ³n en conjuntos train/test (80/20).

Evaluar balance de clases (dataset estÃ¡ equilibrado â‰ˆ55% autÃ©nticos / 45% falsos).

8) Baseline de Rendimiento

Modelo baseline: RegresiÃ³n LogÃ­stica simple.

MÃ©tricas esperadas: Accuracy ~90% y Recall clase â€œfalsoâ€ >95%.

9) Resultados del EDA

TamaÃ±o y calidad de datos

Filas: 1.372 Â· Columnas: 5

Nulos: 0 (no se requieren imputaciones)

|     Clase | Significado |    Conteo |         % |
| --------: | ----------- | --------: | --------: |
|         0 | AutÃ©ntico   |   **762** | **55.5%** |
|         1 | Falso       |   **610** | **44.5%** |
| **Total** | â€”           | **1.372** |  **100%** |

variance:Los billetes autÃ©nticos suelen tener variance positiva (mayores a 0) y Los billetes falsos suelen tener variance negativa (menores a 0).

skewness:Los billetes autÃ©nticos suelen tener asimetrÃ­a hacia la derecha,los falsos suelen tener asimetrÃ­a neutra o hacia la izquierda  

curtosis:Los billetes falsos presentan mÃ¡s casos con curtosis muy alta â€”es decir, picos muy marcados y valores extremos en la texturaâ€”, mientras que los autÃ©nticos rara vez alcanzan esos extremos. 

entropÃ­a: tienen cajas muy parecidas, no se distingue bien entre autÃ©nticos y falsos: los dos grupos se comportan casi igual.

10) conclusiÃ³n: 

variance > 0 y skewness > 0 â†’ mÃ¡s probable AutÃ©ntico.
variance < 0 y/o curtosis alta â†’ mÃ¡s probable Falso.



# RESUMEN ENTREGA PARTE 2

Este proyecto implementa un pipeline completo de Machine Learning con enfoque en MLOps, cuyo objetivo es entrenar y optimizar un modelo que clasifique billetes entre verdaderos y falsos.

El flujo completo incluye:

ETL â€“ ExtracciÃ³n y limpieza de los datos desde la fuente original.

Feature Engineering â€“ CreaciÃ³n de nuevas variables que enriquecen el dataset.

Entrenamiento con MLflow â€“ Entrenamiento, tracking de experimentos y logging automÃ¡tico de modelos.

OptimizaciÃ³n con Optuna â€“ BÃºsqueda de hiperparÃ¡metros para encontrar el mejor modelo.

ComparaciÃ³n de modelos y mÃ©tricas â€“ EvaluaciÃ³n en un conjunto de prueba.

ğŸ› ï¸ ETL

El mÃ³dulo etl.py se encarga de:

Descargar los datos desde el repositorio UCI (data_banknote_authentication).

Convertirlos en un DataFrame de Pandas.

Asignar nombres a las columnas.

âœ… Resultado: un dataset limpio y estructurado listo para el entrenamiento.

ğŸ§ª Feature Engineering

El mÃ³dulo feature_engineer.py aplica transformaciones sobre el dataset original:

Nuevas variables creadas:

var_entropy_ratio

magnitude

abs_skewness

curtosis_minus_skewness

bucket_curtosis (feature categÃ³rica creada a partir de discretizaciÃ³n).

âœ… Resultado: un dataset enriquecido que mejora la capacidad predictiva del modelo.

âš™ï¸ MLflow â€“ Tracking de Experimentos

Se utilizÃ³ MLflow para:

Registrar parÃ¡metros de los modelos.

Guardar mÃ©tricas de entrenamiento y prueba (accuracy, F1-score, etc).

Almacenar los modelos entrenados para su reutilizaciÃ³n.

ğŸ“¸ Pantallazos importantes:

1) Servidor de MLflow mostrando los experimentos creados.
ğŸ“¸ ![alt text](image.png)

2) Resultados de RandomForest (baseline y V2) con Train y Test Accuracy.

ğŸ“¸ ![alt text](image-1.png)
ğŸ“¸ ![alt text](image-2.png)


3)Resultados de xgboost
ğŸ“¸ ![alt text](image-3.png)

4) Resultados de RandomForest + Optuna mostrando el mejor run.
ğŸ“¸ ![alt text](image-4.png)
Nota: En la imagen se observa el listado de runs generados por Optuna en MLflow. Cada run corresponde a un conjunto distinto de hiperparÃ¡metros probados para el modelo RandomForestClassifier.
El mejor run se identifica en la parte superior de la tabla (mayor valor de f1).


ğŸ” OptimizaciÃ³n con Optuna

Se implementÃ³ la clase TrainMlflowOptuna para optimizar hiperparÃ¡metros.

Se definiÃ³ un espacio de bÃºsqueda para n_estimators, max_depth, min_samples_split, min_samples_leaf y max_features.

Se ejecutaron 30 trials registrando todo en MLflow.

ğŸ“Š Visualizaciones de Optuna:

Se incluyeron visualizaciones para analizar el proceso de optimizaciÃ³n:

Optimization History Plot: muestra cÃ³mo fue mejorando la mÃ©trica F1 a lo largo de los trials.

ğŸ“¸ grÃ¡fico de plot_optimization_history: ![alt text](image-6.png)

Hyperparameter Importances: muestra quÃ© hiperparÃ¡metros tuvieron mayor impacto en el resultado.
ğŸ“¸ grÃ¡fico de plot_param_importances: ![alt text](image-7.png)


Importancia de hiperparÃ¡metros.


ğŸ† Resultados Finales

El mejor modelo encontrado fue:

Modelo: RandomForestClassifier

HiperparÃ¡metros:

{'n_estimators': 187, 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'sqrt'}


MÃ©tricas en test:

Accuracy: 1.00

Precision: 0.99 â€“ 1.00

Recall: 0.99 â€“ 1.00

F1-score: 1.00


ğŸ“¸ ![alt text](image-5.png)